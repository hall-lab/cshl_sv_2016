#!/usr/bin/env python

import pysam
import argparse, sys
import math, time, re
import multiprocessing
from collections import Counter
from argparse import RawTextHelpFormatter
from scipy.stats import norm

__author__ = "Colby Chiang (cc2qe@virginia.edu)"
__version__ = "$Revision: 0.0.1 $"
__date__ = "$Date: 2014-04-28 14:31 $"

# --------------------------------------
# define functions

def get_args():
    parser = argparse.ArgumentParser(formatter_class=RawTextHelpFormatter, description="\
svgt\n\
author: " + __author__ + "\n\
version: " + __version__ + "\n\
description: Compute genotype of structural variants based on breakpoint depth")
    parser.add_argument('-B', '--bam', type=pysam.Samfile, required=True, help='BAM file(s), comma-separated if genotyping multiple BAMs')
    parser.add_argument('-S', '--split_bam', type=pysam.Samfile, required=True, help='split-read bam file for sample')
    parser.add_argument('-v', '--input_vcf', type=argparse.FileType('r'), default=None, help='VCF input (default: stdin)')
    parser.add_argument('-o', '--output_vcf', type=argparse.FileType('w'), default=sys.stdout, help='output VCF to write (default: stdout)')
    parser.add_argument('-m', '--mean_frag_size', type=float, required=False, help='mean fragment size of library [auto]')
    parser.add_argument('-sd', '--sd_frag_size', type=float, required=False, help='standard deviation of fragment size of library [auto]')
    parser.add_argument('-f', '--splflank', type=int, required=False, default=20, help='min number of split read query bases flanking breakpoint on either side [20]')
    parser.add_argument('-F', '--discflank', type=int, required=False, default=20, help='min number of discordant read query bases flanking breakpoint on either side. (should not exceed read length) [20]')
    parser.add_argument('--split_weight', type=float, required=False, default=1, help='weight for split reads [1]')
    parser.add_argument('--disc_weight', type=float, required=False, default=1, help='weight for discordant paired-end reads [1]')
    parser.add_argument('-rl', '--read_length', type=int, required=False, help='maximum read-length in BAM [auto]')
    parser.add_argument('-d', '--detailed', action='store_true', required=False, help='more detailed VCF format fields')
    parser.add_argument('--debug', action='store_true', help='debugging verbosity')

    # parse the arguments
    args = parser.parse_args()

    # if no input, check if part of pipe and if so, read stdin.
    if args.input_vcf == None:
        if sys.stdin.isatty():
            parser.print_help()
            exit(1)
        else:
            args.input_vcf = sys.stdin
    # send back the user input
    return args

class Vcf(object):
    def __init__(self):
        self.file_format = 'VCFv4.2'
        # self.fasta = fasta
        self.reference = ''
        self.sample_list = []
        self.info_list = []
        self.format_list = []
        self.alt_list = []
        self.add_format('GT', 1, 'String', 'Genotype')

    def add_header(self, header):
        for line in header:
            if line.split('=')[0] == '##fileformat':
                self.file_format = line.rstrip().split('=')[1]
            elif line.split('=')[0] == '##reference':
                self.reference = line.rstrip().split('=')[1]
            elif line.split('=')[0] == '##INFO':
                a = line[line.find('<')+1:line.find('>')]
                r = re.compile(r'(?:[^,\"]|\"[^\"]*\")+')
                self.add_info(*[b.split('=')[1] for b in r.findall(a)])
            elif line.split('=')[0] == '##ALT':
                a = line[line.find('<')+1:line.find('>')]
                r = re.compile(r'(?:[^,\"]|\"[^\"]*\")+')
                self.add_alt(*[b.split('=')[1] for b in r.findall(a)])
            elif line.split('=')[0] == '##FORMAT':
                a = line[line.find('<')+1:line.find('>')]
                r = re.compile(r'(?:[^,\"]|\"[^\"]*\")+')
                self.add_format(*[b.split('=')[1] for b in r.findall(a)])
            elif line[0] == '#' and line[1] != '#':
                self.sample_list = line.rstrip().split('\t')[9:]

    # return the VCF header
    def get_header(self):
        header = '\n'.join(['##fileformat=' + self.file_format,
                            '##fileDate=' + time.strftime('%Y%m%d'),
                            '##reference=' + self.reference] + \
                           [i.hstring for i in self.info_list] + \
                           [a.hstring for a in self.alt_list] + \
                           [f.hstring for f in self.format_list] + \
                           ['\t'.join([
                               '#CHROM',
                               'POS',
                               'ID',
                               'REF',
                               'ALT',
                               'QUAL',
                               'FILTER',
                               'INFO',
                               'FORMAT'] + \
                                      self.sample_list
                                  )])
        return header

    def add_info(self, id, number, type, desc):
        if id not in [i.id for i in self.info_list]:
            inf = self.Info(id, number, type, desc)
            self.info_list.append(inf)

    def add_alt(self, id, desc):
        if id not in [a.id for a in self.alt_list]:
            alt = self.Alt(id, desc)
            self.alt_list.append(alt)

    def add_format(self, id, number, type, desc):
        if id not in [f.id for f in self.format_list]:
            fmt = self.Format(id, number, type, desc)
            self.format_list.append(fmt)

    def add_sample(self, name):
        self.sample_list.append(name)

    class Info(object):
        def __init__(self, id, number, type, desc):
            self.id = str(id)
            self.number = str(number)
            self.type = str(type)
            self.desc = str(desc)
            # strip the double quotes around the string if present
            if self.desc.startswith('"') and self.desc.endswith('"'):
                self.desc = self.desc[1:-1]
            self.hstring = '##INFO=<ID=' + self.id + ',Number=' + self.number + ',Type=' + self.type + ',Description=\"' + self.desc + '\">'

    class Alt(object):
        def __init__(self, id, desc):
            self.id = str(id)
            self.desc = str(desc)
            # strip the double quotes around the string if present
            if self.desc.startswith('"') and self.desc.endswith('"'):
                self.desc = self.desc[1:-1]
            self.hstring = '##ALT=<ID=' + self.id + ',Description=\"' + self.desc + '\">'

    class Format(object):
        def __init__(self, id, number, type, desc):
            self.id = str(id)
            self.number = str(number)
            self.type = str(type)
            self.desc = str(desc)
            # strip the double quotes around the string if present
            if self.desc.startswith('"') and self.desc.endswith('"'):
                self.desc = self.desc[1:-1]
            self.hstring = '##FORMAT=<ID=' + self.id + ',Number=' + self.number + ',Type=' + self.type + ',Description=\"' + self.desc + '\">'

class Variant(object):
    def __init__(self, var_list, vcf):
        self.chrom = var_list[0]
        self.pos = int(var_list[1])
        self.var_id = var_list[2]
        self.ref = var_list[3]
        self.alt = var_list[4]
        self.qual = float(var_list[5])
        self.filter = var_list[6]
        self.sample_list = vcf.sample_list
        self.info_list = vcf.info_list
        self.info = dict()
        self.format_list = vcf.format_list
        self.active_formats = list()
        self.gts = dict()
        # make a genotype for each sample at variant
        for i in xrange(len(self.sample_list)):
            s_gt = var_list[9+i].split(':')[0]
            s = self.sample_list[i]
            self.gts[s] = Genotype(self, s, s_gt)
        # import the existing fmt fields
        for i in xrange(len(self.sample_list)):
            s = self.sample_list[i]
            for j in zip(var_list[8].split(':'), var_list[9+i].split(':')):
                self.gts[s].set_format(j[0], j[1])

        self.info = dict()
        i_split = [a.split('=') for a in var_list[7].split(';')] # temp list of split info column
        for i in i_split:
            if len(i) == 1:
                i.append(True)
            self.info[i[0]] = i[1]

    def set_info(self, field, value):
        if field in [i.id for i in self.info_list]:
            self.info[field] = value
        else:
            sys.stderr.write('\nError: invalid INFO field, \"' + field + '\"\n')
            exit(1)

    def get_info(self, field):
        return self.info[field]

    def get_info_string(self):
        i_list = list()
        for info_field in self.info_list:
            if info_field.id in self.info.keys():
                if info_field.type == 'Flag':
                    i_list.append(info_field.id)
                else:
                    i_list.append('%s=%s' % (info_field.id, self.info[info_field.id]))
        return ';'.join(i_list)

    def get_format_string(self):
        f_list = list()
        for f in self.format_list:
            if f.id in self.active_formats:
                f_list.append(f.id)
        return ':'.join(f_list)

    def genotype(self, sample_name):
        if sample_name in self.sample_list:
            return self.gts[sample_name]
        else:
            sys.stderr.write('\nError: invalid sample name, \"' + sample_name + '\"\n')

    def get_var_string(self):
        s = '\t'.join(map(str,[
            self.chrom,
            self.pos,
            self.var_id,
            self.ref,
            self.alt,
            '%0.2f' % self.qual,
            self.filter,
            self.get_info_string(),
            self.get_format_string(),
            '\t'.join(self.genotype(s).get_gt_string() for s in self.sample_list)
        ]))
        return s

class Genotype(object):
    def __init__(self, variant, sample_name, gt):
        self.format = dict()
        self.variant = variant
        self.set_format('GT', gt)

    def set_format(self, field, value):
        if field in [i.id for i in self.variant.format_list]:
            self.format[field] = value
            if field not in self.variant.active_formats:
                self.variant.active_formats.append(field)
                # sort it to be in the same order as the format_list in header
                self.variant.active_formats.sort(key=lambda x: [f.id for f in self.variant.format_list].index(x))
        else:
            sys.stderr.write('\nError: invalid FORMAT field, \"' + field + '\"\n')
            exit(1)

    def get_format(self, field):
        return self.format[field]

    def get_gt_string(self):
        g_list = list()
        for f in self.variant.active_formats:
            if f in self.format:
                if type(self.format[f]) == float:
                    g_list.append('%0.2f' % self.format[f])
                else:
                    g_list.append(self.format[f])
            else:
                g_list.append('.')
        return ':'.join(map(str,g_list))

class Bed(object):
    def __init__(self, bedList):
        self.chrom = bedList[0]
        self.start = int(bedList[1])
        self.end = int(bedList[2])
        if len(bedList) > 4:
            self.misc = bedList[3:]

# efficient combinatorial function to handle extremely large numbers
def log_choose(n, k):
    r = 0.0
    # swap for efficiency if k is more than half of n
    if k * 2 > n:
        k = n - k

    for  d in xrange(1,k+1):
        r += math.log(n, 10)
        r -= math.log(d, 10)
        n -= 1

    return r

# return the genotype and log10 p-value
def bayes_gt(ref, alt, is_dup):
    # probability of seeing an alt read with true genotype of of hom_ref, het, hom_alt respectively
    if is_dup: # specialized logic to handle non-destructive events such as duplications
        p_alt = [0.1, 0.3, 0.5]
    else:
        p_alt = [0.1, 0.4, 0.8]

    total = ref + alt
    
    lp_homref = log_choose(total, alt) + alt * math.log(p_alt[0], 10) + ref * math.log(1 - p_alt[0], 10)
    lp_het = log_choose(total, alt) + alt * math.log(p_alt[1], 10) + ref * math.log(1 - p_alt[1], 10)
    lp_homalt = log_choose(total, alt) + alt * math.log(p_alt[2], 10) + ref * math.log(1 - p_alt[2], 10)

    return (lp_homref, lp_het, lp_homalt)

# return the 5' alignment coordinate of the mate read by parsing the MC (mate cigar) SAM field
def get_mate_5prime(bam, read):
    # if 'MC' in [t[0] for t in read.tags]:
    try:
        mc = read.opt('MC') # the mate CIGAR string
        if mc == '*':
            return
        keys = re.findall('[MIDNSHPX=]+', mc)
        nums = map(int, re.findall('[^MIDNSHPX=]+', mc))

        p = read.pnext
        for i in xrange(len(keys)):
            k = keys[i]
            n = nums[i]
            if k == 'M' or k == 'N' or k == 'D':
                p += n
            # if k == 'I' or k == 'P' or k == 'S' or k == 'H':
            #     pass
    except KeyError:
        p = bam.mate(read).aend
    return p

def get_mate_mapq(bam, read):
    # if 'MQ' in [t[0] for t in read.tags]:
    try:
        mq = read.opt('MQ') # the mate mapq score
        if mq == '*':
            return
    except KeyError:
        mq = bam.mate(read).mapq
    return mq

# calculate the probability that a read is concordant at a deletion breakpoint,
# given the putative deletion size and insert distribution of the library.
def p_concordant(read_ospan, var_length, mean_ospan, sd_ospan):
    conc_z = (read_ospan - mean_ospan) / sd_ospan
    p = 1 - norm.cdf(conc_z)

    disc_z = (read_ospan - var_length - mean_ospan) / sd_ospan
    q = norm.cdf(disc_z)

    if p + q == 0:
        return 0
    else:
        return p / (p + q)

def count_pairedend(chrom, pos, mate_chrom, mate_pos, o1, o2, svtype, mean_ospan, sd_ospan, z, discflank, read_length, mybam):
    conc_counter = 0
    disc_counter = 0
    conc_scaled_counter = 0
    disc_scaled_counter = 0

    if o1 == '+':
        # survey for concordant read pairs
        for read in mybam.fetch(chrom, pos - (mean_ospan + sd_ospan * z), pos):
            if read.is_reverse or not read.mate_is_reverse or read.is_secondary or read.is_unmapped or read.mate_is_unmapped or read.is_duplicate or read.pos + discflank > pos or read.pnext + read_length - discflank < pos or read.tid != read.rnext:
                continue
            else:
                mate_mapq = get_mate_mapq(mybam, read)
                ospan = get_mate_5prime(mybam, read) - read.pos
                prob_conc = p_concordant(ospan, abs(mate_pos - pos), mean_ospan, sd_ospan)

                ispan1 = read.pos + discflank
                ispan2 = get_mate_5prime(mybam, read) - discflank - 1 # speed up here
                ispan = ispan2 - ispan1

                if ispan2 > pos:
                    conc_counter += 1
                    conc_scaled_counter += prob_conc * (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                    # if a deletion, iterate the discordants for these too
                    if svtype == 'DEL':
                        disc_counter += 1
                        disc_scaled_counter += (1 - prob_conc) * (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))

        # now look at discordants for corresponding SV types
        if svtype != 'DEL':
            for read in mybam.fetch(chrom, pos - (mean_ospan + sd_ospan * z), pos):
                if read.is_reverse or read.is_secondary or read.is_unmapped or read.mate_is_unmapped or read.is_duplicate or read.pos + discflank > pos or mybam.getrname(read.rnext) != mate_chrom:
                    continue

                mate_mapq = get_mate_mapq(mybam, read) # move this for speed
                mate_5prime = get_mate_5prime(mybam, read)
                if svtype == 'DUP':
                    if not read.mate_is_reverse or read.pnext > read.pos or read.tid != read.rnext:
                        continue
                    ispan1 = read.pos + discflank
                    ispan2 = mate_5prime - discflank - 1
                    # ospan = (pos - read.pos) + (mate_5prime - mate_pos)
                    if ispan1 < pos: # and ispan2 > mate_pos and ospan < (mean_ospan + sd_ospan * z):
                        # print ispan2, pos, mate_pos, 'mate'
                        disc_counter += 1
                        disc_scaled_counter += (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                elif svtype == 'INV':
                    if read.mate_is_reverse:
                        continue
                    ispan1 = read.pos + discflank
                    ispan2 = read.pnext + discflank
                    # ospan = (pos - read.pos) + (mate_pos - read.pnext)
                    if ispan1 < pos: # and ispan2 < mate_pos and ospan < (mean_ospan + sd_ospan * z):
                        disc_counter += 1
                        disc_scaled_counter += (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                elif svtype == 'BND':
                    if o2 == '-':
                        if not read.mate_is_reverse or read.pnext + read_length - discflank < mate_pos:
                            continue
                        ispan1 = read.pos + discflank
                        ispan2 = mate_5prime - discflank - 1
                        # ospan = (pos - read.pos) + (mate_5prime - mate_pos)
                        if ispan1 < pos:
                            disc_counter += 1
                            disc_scaled_counter += (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                    if o2 == '+':
                        if read.mate_is_reverse or read.pnext + discflank > mate_pos:
                            continue
                        ispan1 = read.pos + discflank
                        ispan2 = read.pnext + discflank
                        if ispan1 < pos:
                            disc_counter += 1
                            disc_scaled_counter += (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))

    elif o1 == '-':
        # survey for concordant read pairs
        for read in mybam.fetch(chrom, pos, pos + (mean_ospan + sd_ospan * z)):
            if not read.is_reverse or read.mate_is_reverse or read.is_secondary or read.is_unmapped or read.mate_is_unmapped or read.is_duplicate or read.aend - discflank < pos or read.pnext + discflank > pos or read.tid != read.rnext:
                continue
            else:
                mate_mapq = get_mate_mapq(mybam, read)
                ospan = read.aend - read.pnext
                prob_conc = p_concordant(ospan, abs(mate_pos - pos), mean_ospan, sd_ospan)

                ispan1 = read.aend - discflank - 1
                ispan2 = read.pnext + discflank
                ispan = ispan1 - ispan2

                if ispan2 < pos:
                    conc_counter += 1
                    conc_scaled_counter += prob_conc * (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                    if svtype == 'DEL':
                        disc_counter += 1
                        disc_scaled_counter += (1 - prob_conc) * (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
        
        # now look at discordants for corresponding SV types
        if svtype != 'DEL':
            for read in mybam.fetch(chrom, pos, pos + (mean_ospan + sd_ospan * z)):
                if not read.is_reverse or read.is_secondary or read.is_unmapped or read.mate_is_unmapped or read.is_duplicate or read.aend - discflank < pos or mybam.getrname(read.rnext) != mate_chrom:
                    continue

                mate_mapq = get_mate_mapq(mybam, read) # move this for speed
                mate_5prime = get_mate_5prime(mybam, read)

                if svtype == 'DUP':
                    if read.mate_is_reverse or read.pnext < read.pos or read.tid != read.rnext:
                        continue
                    ispan1 = read.aend - discflank - 1
                    ispan2 = read.pnext + discflank
                    if ispan1 > pos:
                        disc_counter += 1
                        disc_scaled_counter += (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                elif svtype == 'INV':
                    if not read.mate_is_reverse:
                        continue
                    ispan1 = read.aend - discflank - 1
                    ispan2 = mate_5prime - discflank - 1
                    if ispan1 > pos:
                        disc_counter += 1
                        disc_scaled_counter += (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                elif svtype == 'BND':
                    if o2 == '-':
                        if not read.mate_is_reverse or read.pnext + read_length - discflank < mate_pos:
                            continue
                        ispan1 = read.aend - discflank - 1
                        ispan2 = mate_5prime - discflank - 1
                        if ispan1 > pos:
                            disc_counter += 1
                            disc_scaled_counter += (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                    if o2 == '+':
                        if read.mate_is_reverse or read.pnext + discflank > mate_pos:
                            continue
                        ispan1 = read.aend - discflank - 1
                        ispan2 = read.pnext + discflank
                        if ispan1 > pos:
                            disc_counter += 1
                            disc_scaled_counter += (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))

    return (conc_counter, disc_counter, conc_scaled_counter, disc_scaled_counter)

def insert_dist(bam):
    num_samp = 1000000
    counter = 0
    skip = 5000000
    skip_counter = 0
    ins_list = []
    for read in bam.fetch():
        if skip_counter < skip:
            skip_counter += 1
            continue
        if read.is_proper_pair and not read.is_reverse and not read.is_secondary:
            ins_list.append(read.tlen)
            counter += 1
        if counter == num_samp:
            break
    mean = sum(ins_list)/float(len(ins_list))
    v = 0
    for i in ins_list:
        v += (i-mean)**2
    variance = v/float(len(ins_list))
    stdev = variance**(0.5)
    return (mean, stdev)

def get_read_length(bam):
    max_rl = 0
    counter = 0
    num_samp = 10000
    for read in bam.fetch():
        if read.qlen > max_rl:
            max_rl = read.qlen
        if counter == num_samp:
            break
        counter += 1
    return max_rl
        
# primary function
def sv_genotype(vcf_file, bam, spl_bam, vcf_out, splflank, discflank, mean_ospan, sd_ospan, read_length, split_weight, disc_weight, detailed, debug):
    # sample insert size distribution
    if mean_ospan == None or sd_ospan == None:
        (mean_ospan, sd_ospan) = insert_dist(bam)

    # get read length if not specified.
    if read_length == None:
        read_length = get_read_length(bam)

    z = 3
    padding = 30
    in_header = True
    header = []
    breakend_dict = {} # cache to hold unmatched generic breakends for genotyping
    vcf = Vcf()

    # first get the sample name from the bam file
    sample = bam.header['RG'][0]['SM']

    mean_ispan = mean_ospan - (2 * discflank)
    sd_ispan = sd_ospan

    for line in vcf_file:
        if in_header:
            if line[0] == '#':
                header.append(line) 
                if line[1] != '#':
                    vcf_samples = line.rstrip().split('\t')[9:]
                continue
            else:
                in_header = False
                vcf.add_header(header)
                vcf.add_format('RO', 1, 'Integer', 'Reference allele observation count, with partial observations recorded fractionally')
                vcf.add_format('AO', 'A', 'Integer', 'Alternate allele observations, with partial observations recorded fractionally')
                if detailed:
                    vcf.add_format('RS', 1, 'Integer', 'Reference allele split-read observation count, with partial observations recorded fractionally')
                    vcf.add_format('AS', 'A', 'Integer', 'Alternate allele split-read observation count, with partial observations recorded fractionally')
                    vcf.add_format('RP', 1, 'Integer', 'Reference allele paired-end observation count, with partial observations recorded fractionally')
                    vcf.add_format('AP', 'A', 'Integer', 'Alternate allele paired-end observation count, with partial observations recorded fractionally')
                vcf.add_format('SQ', 1, 'Float', 'Phred-scaled probability that this site is variant (non-reference in this sample')
                vcf.add_format('GL', 'G', 'Float', 'Genotype Likelihood, log10-scaled likelihoods of the data given the called genotype for each possible genotype generated from the reference and alternate alleles given the sample ploidy')
                vcf_out.write(vcf.get_header() + '\n')

        v = line.rstrip().split('\t')
        var = Variant(v, vcf)

        # genotype generic breakends
        if var.info['SVTYPE']=='BND':
            if var.info['MATEID'] in breakend_dict:
                if 'PRIN' in breakend_dict[var.info['MATEID']].info:
                    var2 = var
                    var = breakend_dict[var.info['MATEID']]
                    chromA = var.chrom
                    chromB = var2.chrom
                    posA = var.pos
                    posB = var2.pos

                    # infer the strands from the alt allele
                    if var.alt[-1] == '[' or var.alt[-1] == ']':
                        o1 = '+'
                    else: o1 = '-'
                    if var2.alt[-1] == '[' or var2.alt[-1] == ']':
                        o2 = '+'
                    else: o2 = '-'
                elif 'PRIN' in var.info:
                    var2 = breakend_dict[var.info['MATEID']]
                    chromA = var.chrom
                    chromB = var2.chrom
                    posA = var.pos
                    posB = var2.pos
                    
                    # infer the strands from the alt allele
                    if var.alt[-1] == '[' or var.alt[-1] == ']':
                        o1 = '+'
                    else: o1 = '-'
                    if var2.alt[-1] == '[' or var2.alt[-1] == ']':
                        o2 = '+'
                    else: o2 = '-'
            else:
                breakend_dict[var.var_id] = var
                continue
        else:
            chromA = var.chrom
            chromB = var.chrom
            posA = var.pos
            posB = int(var.get_info('END'))
            o1, o2 =  list(var.get_info('STR').split(',')[0].split(':')[0]) # currently ignores the other side for two-sided inversions

        # increment the negative strand values (note position in VCF should be the base immediately left of the breakpoint junction)
        if o1 == '-': posA += 1
        if o2 == '-': posB += 1
        # if debug: print posA, posB

        '''
        Breakend A
        '''
        # Count splitters
        ref_counter_a = Counter()
        spl_counter_a = Counter()
        ref_scaled_counter_a = Counter()
        spl_scaled_counter_a = Counter()

        for ref_read in bam.fetch(chromA, posA - padding, posA + padding + 1):
            if not ref_read.is_duplicate and not ref_read.is_unmapped:
                for p in xrange(ref_read.pos + 1, ref_read.aend + 1):
                    if p - ref_read.pos >= splflank and ref_read.aend - p >= splflank:
                        ref_counter_a[p] += 1
                        ref_scaled_counter_a[p] += (1-10**(-ref_read.mapq/10.0))
        for spl_read in spl_bam.fetch(chromA, posA - padding, posA + padding + 1):
            if not spl_read.is_duplicate and not spl_read.is_unmapped:
                if o1 == '+' and spl_read.cigar[0][0] == 0:
                    # if debug: print 'o1+', spl_read.aend
                    spl_counter_a[spl_read.aend] += 1
                    spl_scaled_counter_a[spl_read.aend] += (1-10**(-spl_read.mapq/10.0))
                elif o1 == '-' and spl_read.cigar[-1][0] == 0:
                    # if debug: print 'o1-', spl_read.pos + 1
                    spl_counter_a[spl_read.pos + 1] += 1
                    spl_scaled_counter_a[spl_read.pos + 1] += (1-10**(-spl_read.mapq/10.0))

        # Count paired-end discordant and concordants
        (conc_counter_a, disc_counter_a, conc_scaled_counter_a, disc_scaled_counter_a) = count_pairedend(chromA, posA, chromB, posB, o1, o2, var.info['SVTYPE'], mean_ospan, sd_ospan, z, discflank, read_length, bam)
        # if var.info['SVTYPE'] == 'INV': # if two-sided inversion, examine both breakpoints
        #     if o1 == '+':
        #         opp_strand = '-'
        #     else:
        #         opp_strand = '+'
        #     (conc_counter_a, disc_counter_a, conc_scaled_counter_a, disc_scaled_counter_a) = count_pairedend(chromA, posA, chromB, posB, opp_strand, opp_strand, var.info['SVTYPE'], mean_ospan, sd_ospan, z, discflank, read_length, bam)

        '''
        Breakend B
        '''
        # Count splitters
        ref_counter_b = Counter()
        spl_counter_b = Counter()
        ref_scaled_counter_b = Counter()
        spl_scaled_counter_b = Counter()

        for ref_read in bam.fetch(chromB, posB - padding, posB + padding + 1):
            if not ref_read.is_duplicate and not ref_read.is_unmapped:
                for p in xrange(ref_read.pos + 1, ref_read.aend + 1):
                    if p - ref_read.pos >= splflank and ref_read.aend - p >= splflank:
                        ref_counter_b[p] += 1
                        ref_scaled_counter_b[p] += (1-10**(-ref_read.mapq/10.0))
        for spl_read in spl_bam.fetch(chromB, posB - padding, posB + padding + 1):
            if not spl_read.is_duplicate and not spl_read.is_unmapped:
                if o2 == '+' and spl_read.cigar[0][0] == 0:
                    spl_counter_b[spl_read.aend] += 1
                    # if debug: print 'o2+', spl_read.aend
                    spl_scaled_counter_b[spl_read.aend] += (1-10**(-spl_read.mapq/10.0))
                elif o2 == '-' and spl_read.cigar[-1][0] == 0:
                    # if debug: print 'o2-', spl_read.pos + 1
                    spl_counter_b[spl_read.pos + 1] += 1
                    spl_scaled_counter_b[spl_read.pos + 1] += (1-10**(-spl_read.mapq/10.0))

        # Count paired-end discordants and concordants
        (conc_counter_b, disc_counter_b, conc_scaled_counter_b, disc_scaled_counter_b) = count_pairedend(chromB, posB, chromA, posA, o2, o1, var.info['SVTYPE'], mean_ospan, sd_ospan, z, discflank, read_length, bam)

        if debug:
            print 'sr_a', ref_counter_a[posA], spl_counter_a[posA]
            print 'pe_a', conc_counter_a, disc_counter_a
            print 'sr_b', ref_counter_b[posB], spl_counter_b[posB]
            print 'pe_b', conc_counter_b, disc_counter_b
            print 'sr_a_scaled', ref_scaled_counter_a[posA], spl_scaled_counter_a[posA]
            print 'pe_a_scaled', conc_scaled_counter_a, disc_scaled_counter_a
            print 'sr_b_scaled', ref_scaled_counter_b[posB], spl_scaled_counter_b[posB]
            print 'pe_b_scaled', conc_scaled_counter_b, disc_scaled_counter_b

        # merge the breakend support
        split_ref = 0 # set these to zero unless there are informative alt bases for the ev type
        disc_ref = 0
        split_alt = spl_counter_a[posA] + spl_counter_b[posB]
        if split_alt > 0:
            split_ref = ref_counter_a[posA] + ref_counter_b[posB]
        disc_alt = disc_counter_a + disc_counter_b
        if disc_alt > 0:
            disc_ref = conc_counter_a + conc_counter_b
        if split_alt == 0 and disc_alt == 0:
            split_ref = ref_counter_a[posA] + ref_counter_b[posB]
            disc_ref = conc_counter_a + conc_counter_b

        split_scaled_ref = 0 # set these to zero unless there are informative alt bases for the ev type
        disc_scaled_ref = 0
        split_scaled_alt = spl_scaled_counter_a[posA] + spl_scaled_counter_b[posB]
        if int(split_scaled_alt) > 0:
            split_scaled_ref = ref_scaled_counter_a[posA] + ref_scaled_counter_b[posB]
        disc_scaled_alt = disc_scaled_counter_a + disc_scaled_counter_b
        if int(disc_scaled_alt) > 0:
            disc_scaled_ref = conc_scaled_counter_a + conc_scaled_counter_b
        if int(split_scaled_alt) == 0 and int(disc_scaled_alt) == 0: # if no alt alleles, set reference
            split_scaled_ref = ref_scaled_counter_a[posA] + ref_scaled_counter_b[posB]
            disc_scaled_ref = conc_scaled_counter_a + conc_scaled_counter_b
            

        if split_scaled_alt + split_scaled_ref + disc_scaled_alt + disc_scaled_ref > 0:
            # get bayesian classifier
            if var.info['SVTYPE'] == "DUP": is_dup = True
            else: is_dup = False
            gt_lplist = bayes_gt(int(split_weight * split_scaled_ref) + int(disc_weight * disc_scaled_ref), int(split_weight * split_scaled_alt) + int(disc_weight * disc_scaled_alt), is_dup)
            gt_idx = gt_lplist.index(max(gt_lplist[1:]))

            # print log probabilities of homref, het, homalt
            if debug:
                print gt_lplist

            # set the overall variant QUAL score and sample specific fields
            var.genotype(sample).set_format('GL', ','.join(['%.0f' % x for x in gt_lplist]))
            var.genotype(sample).set_format('DP', int(split_scaled_ref + split_scaled_alt + disc_scaled_ref + disc_scaled_alt))
            var.genotype(sample).set_format('AO', int(split_scaled_alt + disc_scaled_alt))
            var.genotype(sample).set_format('RO', int(split_scaled_ref + disc_scaled_ref))
            if detailed:
                var.genotype(sample).set_format('AS', int(split_scaled_alt))
                var.genotype(sample).set_format('RS', int(split_scaled_ref))
                var.genotype(sample).set_format('AP', int(disc_scaled_alt))
                var.genotype(sample).set_format('RP', int(disc_scaled_ref))

            # don't genotype if LUMPY call is reference
            if var.genotype(sample).get_format('GT') == '0/0':
                gt_idx = 0
                var.genotype(sample).set_format('GQ', -10 * (gt_lplist[gt_idx] - math.log(sum(10**x for x in gt_lplist),10) ))
            else:
                # assign genotypes
                sample_qual = -10 * (gt_lplist[0] - math.log(sum(10**x for x in gt_lplist),10) ) # phred-scaled probability site is non-reference in this sample
                var.genotype(sample).set_format('GQ', -10 * (gt_lplist[gt_idx] - math.log(sum(10**x for x in gt_lplist),10) ))
                var.genotype(sample).set_format('SQ', sample_qual)
                var.qual += sample_qual
                if gt_idx == 1:
                    var.genotype(sample).set_format('GT', '0/1')
                elif gt_idx == 2:
                    var.genotype(sample).set_format('GT', '1/1')
                elif gt_idx == 0: # should never occur
                    var.genotype(sample).set_format('GT', '0/0')
        else:
            var.genotype(sample).set_format('GT', './.')
            var.qual = 0
            var.genotype(sample).set_format('GQ', '.')
            var.genotype(sample).set_format('GL', '.')
            var.genotype(sample).set_format('DP', 0)
            var.genotype(sample).set_format('AO', 0)
            var.genotype(sample).set_format('RO', 0)
            if detailed:
                var.genotype(sample).set_format('AS', 0)
                var.genotype(sample).set_format('RS', 0)
                var.genotype(sample).set_format('AP', 0)
                var.genotype(sample).set_format('RP', 0)

        vcf_out.write(var.get_var_string() + '\n')
        if var.info['SVTYPE'] == 'BND':
            var2.qual = var.qual
            var2.active_formats = var.active_formats
            var2.genotype = var.genotype
            vcf_out.write(var2.get_var_string() + '\n')
    vcf_out.close()
    
    return

# --------------------------------------
# main function

def main():
    # parse the command line args
    args = get_args()

    # call primary function
    sv_genotype(args.input_vcf, args.bam, args.split_bam, args.output_vcf, args.splflank, args.discflank, args.mean_frag_size, args.sd_frag_size, args.read_length, args.split_weight, args.disc_weight, args.detailed, args.debug)

    # close the files
    args.input_vcf.close()

# initialize the script
if __name__ == '__main__':
    try:
        sys.exit(main())
    except IOError, e:
        if e.errno != 32:  # ignore SIGPIPE
            raise 
